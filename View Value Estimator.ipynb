{
 "cells": [
  {
   "cell_type": "code",
   "id": "b75781533d00711f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T11:55:09.868539Z",
     "start_time": "2025-11-01T11:55:06.862254Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from fredapi import Fred\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T11:55:10.330945Z",
     "start_time": "2025-11-01T11:55:10.283019Z"
    }
   },
   "source": [
    "df = pd.read_csv(\"data.csv\", sep=\";\", decimal=\",\")\n",
    "df = df.rename(columns={\n",
    "    \"Column1\": \"Date\",\n",
    "    \"Column2\": \"SPX\",\n",
    "    \"Column3\": \"S5SFTW\",\n",
    "    \"Column4\": \"S5PHRM\",\n",
    "    \"Column5\": \"S5CPGS\",\n",
    "    \"Column6\": \"S5ENRSX\",\n",
    "    \"Column7\": \"S5FDBT\",\n",
    "    \"Column8\": \"S5TECH\",\n",
    "    \"Column9\": \"S5RETL\",\n",
    "    \"Column10\": \"S5BANKX\",\n",
    "    \"Column11\": \"S5HCES\",\n",
    "    \"Column12\": \"S5DIVF\",\n",
    "    \"Column13\": \"S5UTILX\",\n",
    "    \"Column14\": \"S5MEDA\",\n",
    "    \"Column15\": \"S5REAL\",\n",
    "    \"Column16\": \"S5TELSX\",\n",
    "    \"Column17\": \"S5MATRX\",\n",
    "    \"Column18\": \"S5INSU\",\n",
    "    \"Column19\": \"S5FDSR\",\n",
    "    \"Column20\": \"S5HOUS\",\n",
    "    \"Column21\": \"S5SSEQX\",\n",
    "    \"Column22\": \"S5TRAN\",\n",
    "    \"Column23\": \"S5HOTR\",\n",
    "    \"Column24\": \"S5CODU\",\n",
    "    \"Column25\": \"S5AUCO\",\n",
    "    \"Column26\": \"S5COMS\",\n",
    "})\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%d/%m/%Y\")"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T11:55:10.385115Z",
     "start_time": "2025-11-01T11:55:10.378415Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def GetReturn(df,date,lookback=180):\n",
    "    date=pd.to_datetime(date)\n",
    "    if date not in df[\"Date\"].values:#add breaker if windows not in df\n",
    "        raise ValueError(\"Date not in dataframe\")\n",
    "    returns_df = df[[\"Date\",\"S5SFTW\",\"S5PHRM\",\"S5CPGS\",\"S5ENRSX\",\"S5FDBT\",\"S5TECH\",\"S5RETL\",\"S5BANKX\",\"S5HCES\",\"S5DIVF\",\"S5UTILX\",\"S5MEDA\",\"S5REAL\",\"S5TELSX\",\"S5MATRX\",\"S5INSU\",\"S5FDSR\",\"S5HOUS\",\"S5SSEQX\",\"S5TRAN\",\"S5HOTR\",\"S5CODU\",\"S5AUCO\",\"S5COMS\"]].copy()\n",
    "\n",
    "    date_list=returns_df.drop(columns=\"Date\")\n",
    "    date_index = returns_df.index[returns_df[\"Date\"] == date][0]\n",
    "    returns_df=returns_df[(returns_df.index<=date_index) & (returns_df.index>=date_index-lookback) ]\n",
    "    returns_df.drop(columns=\"Date\",inplace=True)\n",
    "\n",
    "    returns_df = np.log(returns_df/ returns_df.shift(1))\n",
    "    returns_df.dropna(inplace=True)\n",
    "    #print(returns_df.std().mean()) #verification if std is around 1% daily\n",
    "\n",
    "    return returns_df\n",
    "\n",
    "\n",
    "def GetReturnSPX(df,date,lookback=180):\n",
    "    date=pd.to_datetime(date)\n",
    "    if date not in df[\"Date\"].values:#add breaker if windows not in df\n",
    "        raise ValueError(\"Date not in dataframe\")\n",
    "    returns_df = df[[\"Date\",\"SPX\"]].copy()\n",
    "\n",
    "    date_list=returns_df.drop(columns=\"Date\")\n",
    "    date_index = returns_df.index[returns_df[\"Date\"] == date][0]\n",
    "    returns_df=returns_df[(returns_df.index<=date_index) & (returns_df.index>=date_index-lookback) ]\n",
    "    returns_df.drop(columns=\"Date\",inplace=True)\n",
    "\n",
    "    returns_df = np.log(returns_df/ returns_df.shift(1))\n",
    "    returns_df.dropna(inplace=True)\n",
    "    #print(returns_df.std().mean()) #verification if std is around 1% daily\n",
    "\n",
    "    return returns_df\n",
    "\n",
    "#Returns=GetReturn(df,\"2020-05-11\",lookback=180)\n",
    "#ReturnsSPX=GetReturnSPX(df,\"2020-05-11\",lookback=180)"
   ],
   "id": "63ccf7fcc29a8cf7",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T11:55:10.399663Z",
     "start_time": "2025-11-01T11:55:10.396783Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def GetSigma(df,date,lookback=180):\n",
    "    returns_df=GetReturn(df,date,lookback=lookback)\n",
    "    #covariance matric from returns_df\n",
    "    sigma_windowed=returns_df.cov()\n",
    "\n",
    "    return sigma_windowed\n",
    "\n",
    "#Sigma=GetSigma(df,\"2020-05-11\",lookback=180)"
   ],
   "id": "5e8b24397cfe7ca5",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T11:55:10.420752Z",
     "start_time": "2025-11-01T11:55:10.410114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def GetRfDataframe(df):\n",
    "    fred = Fred(api_key=\"5c742a53d96bd3085e9199dcdb5af60b\")\n",
    "    riskfree = fred.get_series('DFF')\n",
    "    # riskfree = fred.get_series('DTB1MO')\n",
    "\n",
    "    riskfree = riskfree.to_frame(name='FedFunds')\n",
    "    riskfree.index.name = \"Date\"\n",
    "    riskfree = riskfree[riskfree.index >= \"2002-01-01\"]\n",
    "    riskfree[\"FedFunds\"]=riskfree[\"FedFunds\"]/100\n",
    "    list_days_open = pd.to_datetime(df[\"Date\"], dayfirst=True, errors=\"coerce\")\n",
    "    list_days_full = pd.to_datetime(riskfree.index, dayfirst=True, errors=\"coerce\")\n",
    "\n",
    "    list_days_open=[pd.to_datetime(date) for date in list_days_open]\n",
    "    list_days_full=[pd.to_datetime(date) for date in list_days_full]\n",
    "\n",
    "\n",
    "    list_days_open_pondered=[]\n",
    "    riskfree_list=[]\n",
    "    count_list=[]\n",
    "    timestamp=0\n",
    "    while timestamp < len(list_days_full)-1:\n",
    "\n",
    "      if list_days_full[timestamp+1] in list_days_open:\n",
    "            list_days_open_pondered.append(list_days_full[timestamp])\n",
    "            riskfree_list.append(riskfree[\"FedFunds\"].loc[list_days_full[timestamp]])\n",
    "            count_list.append(1)\n",
    "            timestamp += 1\n",
    "\n",
    "      else:\n",
    "          count = 0\n",
    "          timestampbis = timestamp\n",
    "          while (timestamp + 1 < len(list_days_full)) and (list_days_full[timestamp + 1] not in list_days_open):\n",
    "              timestamp += 1\n",
    "              count += 1\n",
    "\n",
    "          list_days_open_pondered.append(list_days_full[timestampbis])  # jour de dÃ©part\n",
    "          riskfree_list.append(riskfree[\"FedFunds\"].loc[list_days_full[timestampbis]])\n",
    "          count_list.append(count+1)\n",
    "          timestamp += 1\n",
    "\n",
    "    RfDf=pd.DataFrame({\"Date\":list_days_open_pondered,\"Rf\":riskfree_list,\"Count\":count_list})\n",
    "    RfDf=RfDf.set_index(\"Date\")\n",
    "    return RfDf\n",
    "\n",
    "\n",
    "def GetRiskFree(df,date,lookback=180):\n",
    "\n",
    "    RfDf=GetRfDataframe(df)\n",
    "    positionOfStartDate=df.index[df[\"Date\"]==pd.to_datetime(date)][0]-lookback\n",
    "    startDate=pd.to_datetime(df.iloc[positionOfStartDate,0])\n",
    "\n",
    "    endDate=pd.to_datetime(date)\n",
    "    RfDf=RfDf[(RfDf.index >= startDate) & (RfDf.index <= endDate )]\n",
    "    CumulativeRf=[]\n",
    "\n",
    "    for i in range(len(RfDf)):\n",
    "      if i==0:\n",
    "        CumulativeRf.append(pow((1+RfDf[\"Rf\"].iloc[i]),(RfDf[\"Count\"].iloc[i]/360)))\n",
    "      else:\n",
    "        CumulativeRf.append(pow((1+RfDf[\"Rf\"].iloc[i]),(RfDf[\"Count\"].iloc[i]/360))*CumulativeRf[i-1])\n",
    "\n",
    "    RfDf[\"CumulativeRf\"]=CumulativeRf\n",
    "    RfDf[\"CumulativeRf\"]= RfDf[\"CumulativeRf\"]-1\n",
    "\n",
    "    return RfDf[\"CumulativeRf\"].iloc[-1]\n",
    "\n",
    "#RiskFree=GetRiskFree(df,\"2020-05-11\",lookback=180)"
   ],
   "id": "9baa47fcf31b0deb",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T11:55:10.434729Z",
     "start_time": "2025-11-01T11:55:10.431831Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def GetWeight(df,date):\n",
    "    #for the moment we will use the equal weight\n",
    "    weight_vector=np.zeros((24,1))\n",
    "    for i in range(0,24):\n",
    "        weight_vector[i]=1/24\n",
    "\n",
    "    return weight_vector\n",
    "#Weight=GetWeight(df,\"2020-05-11\")\n"
   ],
   "id": "195aaba57db66c4c",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T11:55:10.450182Z",
     "start_time": "2025-11-01T11:55:10.445656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def GetLambda(df,date,lookback=180):\n",
    "    returns=GetReturn(df,date,lookback)\n",
    "    returns=returns+1\n",
    "\n",
    "    avg_return=returns.prod()-1 #geometric 180days return\n",
    "    weight_vector=GetWeight(df=0,date=0)\n",
    "\n",
    "    Sigma=GetSigma(df,date,lookback=180)\n",
    "\n",
    "    var = float(weight_vector.T @ Sigma.values @ weight_vector)\n",
    "    lambda_value=(avg_return@weight_vector - GetRiskFree(df,date,lookback=180))/np.sqrt(var)\n",
    "    return lambda_value\n",
    "\n",
    "\n",
    "#Lambda=GetLambda(df,\"2016-05-11\",lookback=180)\n"
   ],
   "id": "aefec1091b17cb9a",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T12:24:25.231363Z",
     "start_time": "2025-11-01T12:24:25.224989Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def GetPMatrix(df,date, lookback,longonly=False,proportion=3,offset=3):\n",
    "    AssetColumns=[\"S5SFTW\",\"S5PHRM\",\"S5CPGS\",\"S5ENRSX\",\"S5FDBT\",\"S5TECH\",\"S5RETL\",\"S5BANKX\",\"S5HCES\",\"S5DIVF\",\"S5UTILX\",\"S5MEDA\",\"S5REAL\",\"S5TELSX\",\"S5MATRX\",\"S5INSU\",\"S5FDSR\",\"S5HOUS\",\"S5SSEQX\",\"S5TRAN\",\"S5HOTR\",\"S5CODU\",\"S5AUCO\",\"S5COMS\"]\n",
    "    bestperformer = []\n",
    "    worstperformer = []\n",
    "    performerc = []\n",
    "    returnBestPerformer=[]\n",
    "    returnWorstPerformer=[]\n",
    "    endDateIndex=df.index[df[\"Date\"]==pd.to_datetime(date)][0]\n",
    "    startDateIndex=df.index[df[\"Date\"]==pd.to_datetime(date)][0]-lookback\n",
    "\n",
    "    for i in range(1, df.shape[1]):  #loop through asset columns\n",
    "        performerc.append((((float(df.iloc[endDateIndex, i]) / float(df.iloc[startDateIndex, i]) - 1) * 100), i - 1))\n",
    "\n",
    "    performerc.sort(reverse=True)\n",
    "    for i in range(proportion):\n",
    "        bestperformer.append(performerc[i][1])\n",
    "        returnBestPerformer.append(performerc[i][0])\n",
    "\n",
    "    for i in range(len(performerc) - offset - proportion, len(performerc) - offset):\n",
    "        if longonly==False:\n",
    "            worstperformer.append(performerc[i][1])\n",
    "            returnWorstPerformer.append(performerc[i][0])\n",
    "\n",
    "    P=np.zeros((1,24))\n",
    "    if longonly==True:\n",
    "        for i in range(len(AssetColumns)):\n",
    "            P[0,i]=-1/(24-proportion)\n",
    "    else :\n",
    "        for i in range(len(AssetColumns)):\n",
    "            P[0,i]=0\n",
    "\n",
    "    for i in range(len(AssetColumns)):\n",
    "        if i in bestperformer:\n",
    "            P[0,i]=1/proportion\n",
    "        elif i in worstperformer and longonly==False:\n",
    "            P[0,i]=-1/proportion\n",
    "\n",
    "\n",
    "    if len(returnWorstPerformer)==0:\n",
    "        returnWorstPerformer.append(0)\n",
    "\n",
    "    spreadLoosersWinnners=np.mean(returnBestPerformer)-np.mean(returnWorstPerformer)\n",
    "    Q=np.array([[spreadLoosersWinnners/100]]) #convert to decimal\n",
    "    return P, Q\n",
    "\n",
    "#PMatrix,TempoQ=PMatrix(df,\"2016-05-11\",lookback=180)"
   ],
   "id": "f4086d5349d997a1",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T11:55:10.480270Z",
     "start_time": "2025-11-01T11:55:10.477393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def GetOmega(PMatrix, Sigma, c=0.99):\n",
    "    #Omega is the uncertainty of the views\n",
    "    factorC=(1/c-1)\n",
    "    Omega=factorC*PMatrix@Sigma@np.transpose(PMatrix)\n",
    "\n",
    "\n",
    "    return Omega"
   ],
   "id": "2a2f7b613eac4ec5",
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "e3cfff2a-f809-481b-9d87-09278a7ad0b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T12:25:01.695938Z",
     "start_time": "2025-11-01T12:24:52.754518Z"
    }
   },
   "source": [
    "def BlackAndLittermanModel(backtestStartDate, rebalancingFrequency, lookbackPeriod, df):\n",
    "    #implement the full backtest of the black and litterman model\n",
    "\n",
    "    #---------\n",
    "    #PARAMETERS\n",
    "    #---------\n",
    "\n",
    "    free_asset=0 #proportion of risk free asset allocated in the benchmark\n",
    "    taux=0.01\n",
    "\n",
    "\n",
    "    Sigma=GetSigma(df,backtestStartDate,lookback=lookbackPeriod)\n",
    "    Lambda=GetLambda(df,backtestStartDate,lookback=lookbackPeriod)\n",
    "    PMatrix,Q= GetPMatrix(df,backtestStartDate, lookback=lookbackPeriod,longonly=True,proportion=3,offset=3)\n",
    "    Omega=GetOmega(PMatrix, Sigma, c=0.5)\n",
    "    rf=GetRiskFree(df,backtestStartDate,lookback=lookbackPeriod)\n",
    "    weights = GetWeight(df, backtestStartDate)\n",
    "    weights = np.array(weights).reshape(-1, 1)\n",
    "    uimplied = Lambda * (Sigma @ weights) + rf\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    optimizedReturn=(np.linalg.inv(np.linalg.inv(taux*Sigma)+np.transpose(PMatrix)@np.linalg.inv(Omega)@PMatrix)) @ (np.linalg.inv(taux*Sigma)@uimplied+np.transpose(PMatrix)@np.linalg.inv(Omega)@Q)\n",
    "\n",
    "    print(\"BL Returns\",optimizedReturn)\n",
    "\n",
    "    #MarkowitzAllocation\n",
    "\n",
    "    WeightBL=np.linalg.inv(Sigma)@(optimizedReturn-rf)/Lambda\n",
    "\n",
    "    print(\"BL Weights\",WeightBL)\n",
    "    print(\"RF Weights\",np.sum(WeightBL))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    pass\n",
    "\n",
    "BlackAndLittermanModel(\"2016-05-11\", rebalancingFrequency=3, lookbackPeriod=180, df=df)\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mbard\\AppData\\Local\\Temp\\ipykernel_30480\\4279076909.py:10: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  var = float(weight_vector.T @ Sigma.values @ weight_vector)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.04761905 -0.04761905 -0.04761905 -0.04761905 -0.04761905  0.33333333\n",
      "  -0.04761905 -0.04761905 -0.04761905 -0.04761905 -0.04761905  0.33333333\n",
      "  -0.04761905 -0.04761905 -0.04761905 -0.04761905 -0.04761905 -0.04761905\n",
      "   0.33333333 -0.04761905 -0.04761905 -0.04761905 -0.04761905 -0.04761905]]\n",
      "BL Returns            0\n",
      "0   0.047301\n",
      "1   0.025796\n",
      "2   0.030325\n",
      "3   0.058077\n",
      "4  -0.003028\n",
      "5   0.145508\n",
      "6   0.018186\n",
      "7   0.041472\n",
      "8   0.007828\n",
      "9   0.043991\n",
      "10 -0.022732\n",
      "11  0.077469\n",
      "12 -0.002259\n",
      "13  0.010344\n",
      "14  0.044479\n",
      "15  0.018046\n",
      "16  0.004182\n",
      "17 -0.007445\n",
      "18  0.127067\n",
      "19  0.042109\n",
      "20  0.025319\n",
      "21  0.005591\n",
      "22  0.057820\n",
      "23  0.026069\n",
      "BL Weights              0\n",
      "0   -28.325068\n",
      "1   -28.325068\n",
      "2   -28.325068\n",
      "3   -28.325068\n",
      "4   -28.325068\n",
      "5   198.608811\n",
      "6   -28.325068\n",
      "7   -28.325068\n",
      "8   -28.325068\n",
      "9   -28.325068\n",
      "10  -28.325068\n",
      "11  198.608811\n",
      "12  -28.325068\n",
      "13  -28.325068\n",
      "14  -28.325068\n",
      "15  -28.325068\n",
      "16  -28.325068\n",
      "17  -28.325068\n",
      "18  198.608811\n",
      "19  -28.325068\n",
      "20  -28.325068\n",
      "21  -28.325068\n",
      "22  -28.325068\n",
      "23  -28.325068\n",
      "RF Weights 0    1.0\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mbard\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:84: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a1f3e2fe36815599"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
